        
import pandas as pd


# ### Exercise 1 (max 2 points)
# Leggere il genoma in una variabile di tipo str.

genome = ""
filename = "nc_051526_1.fasta"


with open(filename, "r") as f:
    for line in f:
            # Rimuoviamo eventuali spazi bianchi all'inizio e alla fine (incluso \n)
            line = line.strip()
            
            # Saltiamo la riga del commento (header) che inizia con '>'
            if line.startswith(">"):
                continue
            
            # Aggiungiamo il contenuto alla stringa del genoma
            genome += line

    print(f"Tipo della variabile: {type(genome)}")

# ### Exercise 2 (max 5 points)
import itertools

# 1. Otteniamo le lettere uniche presenti nel genoma (es: {'A', 'C', 'G', 'T'})
letters = sorted(list(set(genome)))

# 2. Generiamo tutte le possibili triplette (4^3 = 64 combinazioni se le lettere sono 4)
all_triplets = [''.join(t) for t in itertools.product(letters, repeat=3)] #aggiunge tutte le tuple t generate dal prodotto cartesiano intertools

# 3. Filtriamo per considerare ogni tripletta e il suo reverse solo una volta
potential_triplets = set()

for triplet in all_triplets:
    reverse_triplet = triplet[::-1] #parte dalla fine e va all'indietro
    
    # Se il reverse è già nel set, non aggiungiamo questa

    if reverse_triplet not in potential_triplets:
        potential_triplets.add(triplet)

# Trasformiamo in lista per comodità o lasciamo come set
potential_triplets = list(potential_triplets)

# Verifica
print(f"Lettere trovate: {letters}")
print(f"Numero di triplette potenziali (senza duplicati speculari): {len(potential_triplets)}")
print(f"Esempi: {potential_triplets}")

def triplet_in_string(string: str, triplet:str) -> int:
    """
    Calcola quante volte una tripletta o la sua inversa si 
    ripete all'interno di una data stringa
    >>> triplet_in_string('CAATAATCC', 'AAT')
    3
    >>> triplet_in_string('AAAAAAA', 'AAA')
    5
    """
    reversed_triplet = triplet[::-1]
    count = 0
    for i in range (0, len(string)-2):
        a = string[i:i+3]
        if string[i:i+3] == triplet or string[i:i+3] == reversed_triplet:
            count += 1
    return count



# 1. Creiamo un dizionario per raccogliere i conteggi
# Usiamo la funzione definita nell'Esercizio 3 per ogni tripletta potenziale
occurences_data = {}

for t in potential_triplets:
    # Chiamiamo la tua funzione dell'esercizio 3
    count = triplet_in_string(genome, t)
    occurences_data[t] = count

# 2. Creiamo il DataFrame usando le triplette come indice
# Il dizionario passerà le triplette alle righe e i conteggi alla colonna 'occurrences'
df = pd.DataFrame.from_dict(occurences_data, orient='index', columns=['occurrences'])

# 3. Aggiungiamo la colonna 'even' (True se pari, False se dispari)
# Usiamo l'operatore modulo % per verificare la divisibilità per 2
df['even'] = df['occurrences'] % 2 == 0

# Rinominiamo l'indice per chiarezza (opzionale ma consigliato)
df.index.name = 'triplet'

# Verifica i risultati
print(df)

# Controllo specifico richiesto dal testo:
if 'AGG' in df.index:
    print(f"\nOccorrenze di 'AGG': {df.loc['AGG', 'occurrences']}")      


mean = df['occurrences'].mean()
std_dev = df['occurrences'].std()
df['std_num'] = (df['occurrences'] - mean) / std_dev

import matplotlib.pyplot as plt
import numpy as np

# ### Exercise 6 (max 3 points)

# 1. Definiamo la lista dei bin come richiesto: [-3, -2.5, ..., 2.5, 3]
# Possiamo crearla manualmente o con np.arange
bins_list = np.arange(-3,3.5,.5)

# 2. Creiamo l'istogramma
plt.hist(df['std_num'], bins=bins_list, color='skyblue', edgecolor='black', alpha=0.7)

# 3. Aggiungiamo la linea verticale rossa tratteggiata per la media
# La media di una colonna standardizzata è teoricamente 0
mean_std = df['std_num'].mean()
plt.axvline(mean_std, color='red', linestyle='dashed', linewidth=2, label=f'Mean: {mean_std:.2f}')

# 4. Aggiungiamo titoli e legende
plt.title('Distribuzione delle Occorrenze Standardizzate')
plt.xlabel('Valori Standardizzati (std_num)')
plt.ylabel('Frequenza (Numero di triplette)')
plt.legend()

# 5. Salviamo l'immagine
plt.show()


import matplotlib.pyplot as plt

# ### Exercise 7 (max 5 points)

# 1. Prepariamo i dati filtrando per la colonna 'even'
std_even = df.loc[df['even'] == True, 'std_num']
std_odd = df.loc[df['even'] == False, 'std_num']

# 2. Creiamo la figura con una riga e due colonne (1, 2)
# figsize definisce la dimensione (larghezza, altezza)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

# 3. Primo istogramma: Triplette PARI
# L'istogramma ordina automaticamente i valori sull'asse X
ax1.hist(std_even, bins=bins_list, color='skyblue', edgecolor='black', label='Even Triplets')
ax1.set_title('Standardized Occurrences: EVEN')
ax1.set_xlabel('std_num')
ax1.set_ylabel('Frequency')
ax1.legend()

# 4. Secondo istogramma: Triplette DISPARI
ax2.hist(std_odd, bins=bins_list, color='salmon', edgecolor='black', label='Odd Triplets')
ax2.set_title('Standardized Occurrences: ODD')
ax2.set_xlabel('std_num')
ax2.set_ylabel('Frequency')
ax2.legend()

# 5. Ottimizziamo lo spazio tra i grafici e mostriamo/salviamo
plt.tight_layout()
plt.show()

import pymc as pm
import arviz as az

# ### Exercise 8 (max 4 points)

# 1. Prepariamo i dati (estratti nell'esercizio precedente)
data_even = df.loc[df['even'] == True, 'std_num'].values
data_odd = df.loc[df['even'] == False, 'std_num'].values

# 2. Definiamo il modello PyMC
with pm.Model() as biological_model:
    # --- PRIORS (Le nostre stime a priori) ---
    # Media: normale con media 0 e deviazione standard 2
    mu = pm.Normal("mu", mu=0, sigma=2)
    
    # Deviazione standard: esponenziale con lambda = 1
    # Nota: in PyMC Exponential(lam) usa lam=1/scale. Quindi lam=1 va bene.
    sigma = pm.Exponential("sigma", lam=1)
    
    # --- LIKELIHOOD (La verosimiglianza) ---
    # Assumiamo che i dati osservati (sia pari che dispari) seguano 
    # una distribuzione Normale con i parametri mu e sigma definiti sopra
    # Uniamo i dati o definiamo osservazioni separate
    obs_even = pm.Normal("obs_even", mu=mu, sigma=sigma, observed=data_even)
    obs_odd = pm.Normal("obs_odd", mu=mu, sigma=sigma, observed=data_odd)
    
    # --- SAMPLING ---
    # Estraiamo i campioni dalla distribuzione a posteriori
    trace = pm.sample(1000, return_inferencedata=True, progressbar=False)

# 3. Plot delle distribuzioni a posteriori con ArviZ
az.plot_posterior(trace)
plt.show()
